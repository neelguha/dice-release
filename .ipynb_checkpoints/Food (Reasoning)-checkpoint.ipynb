{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from fuzzywuzzy import fuzz\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import random \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "from knowledge_graph import KG\n",
    "from task_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data/food/usage...\n",
      "Loaded 987899 triples.\n"
     ]
    }
   ],
   "source": [
    "kg = KG(\"data/food/usage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: category_prediction\n",
      "category_prediction (train): 13132 samples\n",
      "category_prediction (valid): 1641 samples\n",
      "category_prediction (test): 1642 samples\n",
      "\n",
      "Task: energy_prediction\n",
      "energy_prediction (train): 13600 samples\n",
      "energy_prediction (valid): 1700 samples\n",
      "energy_prediction (test): 1701 samples\n",
      "\n",
      "Task: grade_prediction\n",
      "grade_prediction (train): 13600 samples\n",
      "grade_prediction (valid): 1700 samples\n",
      "grade_prediction (test): 1701 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kg.load_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Nutrition Grade Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct feature dictionaries \n",
    "xtr = kg.tasks['category_prediction']['train']['X']\n",
    "ytr = kg.tasks['category_prediction']['train']['Y']\n",
    "\n",
    "xts = kg.tasks['category_prediction']['test']['X']\n",
    "yts = kg.tasks['category_prediction']['test']['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 712317/712317 [00:00<00:00, 1298007.87it/s]\n",
      "100%|██████████| 88757/88757 [00:00<00:00, 822255.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# featurize training data\n",
    "train_dict = defaultdict(list) # entity -> list of \"$feature $value\" \n",
    "triples = kg.filter_triples(head_filter=xtr)\n",
    "for head, arc, tail, tail_type, _ in tqdm(triples):\n",
    "    if tail_type == \"entity\":\n",
    "        continue \n",
    "    train_dict[head].append(\"%s %s\" % (arc, tail))\n",
    "\n",
    "train_sent = []\n",
    "for entity in xtr:\n",
    "    val_list = train_dict[entity]\n",
    "    train_sent.append(' '.join(val_list))\n",
    "    \n",
    "# featurize test data\n",
    "test_dict = defaultdict(list) # entity -> list of \"$feature $value\" \n",
    "triples = kg.filter_triples(head_filter=xts)\n",
    "for head, arc, tail, tail_type, _ in tqdm(triples):\n",
    "    if tail_type == \"entity\":\n",
    "        continue \n",
    "    test_dict[head].append(\"%s %s\" % (arc, tail))\n",
    "\n",
    "test_sent = []\n",
    "for entity in xts:\n",
    "    val_list = test_dict[entity]\n",
    "    test_sent.append(' '.join(val_list))\n",
    "\n",
    "    \n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "Xtr = vectorizer.fit_transform(train_sent)\n",
    "Xts = vectorizer.transform(test_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "Ytr = mlb.fit_transform(ytr)\n",
    "Yts = mlb.transform(yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit classifier \n",
    "classif = OneVsRestClassifier(SVC(kernel='linear'))\n",
    "classif.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = classif.predict(Xts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.855257. Recall: 0.612395. F1: 0.713732\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1 = evaluate_multilabel_classification(Yts, y_preds)\n",
    "print(\"Precision: %f. Recall: %f. F1: %f\" % (precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Energy Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct feature dictionaries \n",
    "xtr = kg.tasks['energy_prediction']['train']['X']\n",
    "ytr = [float(x) for x in kg.tasks['energy_prediction']['train']['Y']]\n",
    "\n",
    "xts = kg.tasks['energy_prediction']['test']['X']\n",
    "yts = [float(x) for x in kg.tasks['energy_prediction']['test']['Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 736734/736734 [00:00<00:00, 1246211.61it/s]\n",
      "100%|██████████| 92577/92577 [00:00<00:00, 866647.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# featurize training data\n",
    "train_dict = defaultdict(list) # entity -> list of \"$feature $value\" \n",
    "triples = kg.filter_triples(head_filter=xtr)\n",
    "for head, arc, tail, tail_type, _ in tqdm(triples):\n",
    "    if tail_type == \"entity\":\n",
    "        continue \n",
    "    train_dict[head].append(\"%s %s\" % (arc, tail))\n",
    "\n",
    "train_sent = []\n",
    "for entity in xtr:\n",
    "    val_list = train_dict[entity]\n",
    "    train_sent.append(' '.join(val_list))\n",
    "    \n",
    "# featurize test data\n",
    "test_dict = defaultdict(list) # entity -> list of \"$feature $value\" \n",
    "triples = kg.filter_triples(head_filter=xts)\n",
    "for head, arc, tail, tail_type, _ in tqdm(triples):\n",
    "    if tail_type == \"entity\":\n",
    "        continue \n",
    "    test_dict[head].append(\"%s %s\" % (arc, tail))\n",
    "\n",
    "test_sent = []\n",
    "for entity in xts:\n",
    "    val_list = test_dict[entity]\n",
    "    test_sent.append(' '.join(val_list))\n",
    "\n",
    "    \n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "Xtr = vectorizer.fit_transform(train_sent)\n",
    "Xts = vectorizer.transform(test_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(Xtr, ytr)\n",
    "predictions = model.predict(Xts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-square error: 118114.93527223503\n"
     ]
    }
   ],
   "source": [
    "mse = evaluate_regression(yts, predictions)\n",
    "print(\"Mean-square error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Grade Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct feature dictionaries \n",
    "xtr = kg.tasks['grade_prediction']['train']['X']\n",
    "ytr = kg.tasks['grade_prediction']['train']['Y']\n",
    "\n",
    "xts = kg.tasks['grade_prediction']['test']['X']\n",
    "yts = kg.tasks['grade_prediction']['test']['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 738457/738457 [00:00<00:00, 1254897.60it/s]\n",
      "100%|██████████| 92533/92533 [00:00<00:00, 845979.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# featurize training data\n",
    "train_dict = defaultdict(list) # entity -> list of \"$feature $value\" \n",
    "triples = kg.filter_triples(head_filter=xtr)\n",
    "for head, arc, tail, tail_type, _ in tqdm(triples):\n",
    "    if tail_type == \"entity\":\n",
    "        continue \n",
    "    train_dict[head].append(\"%s %s\" % (arc, tail))\n",
    "\n",
    "train_sent = []\n",
    "for entity in xtr:\n",
    "    val_list = train_dict[entity]\n",
    "    train_sent.append(' '.join(val_list))\n",
    "    \n",
    "# featurize test data\n",
    "test_dict = defaultdict(list) # entity -> list of \"$feature $value\" \n",
    "triples = kg.filter_triples(head_filter=xts)\n",
    "for head, arc, tail, tail_type, _ in tqdm(triples):\n",
    "    if tail_type == \"entity\":\n",
    "        continue \n",
    "    test_dict[head].append(\"%s %s\" % (arc, tail))\n",
    "\n",
    "test_sent = []\n",
    "for entity in xts:\n",
    "    val_list = test_dict[entity]\n",
    "    test_sent.append(' '.join(val_list))\n",
    "\n",
    "\n",
    "# vectorize features\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "Xtr = vectorizer.fit_transform(train_sent)\n",
    "Xts = vectorizer.transform(test_sent)\n",
    "\n",
    "# convert grades to labels\n",
    "le = LabelEncoder()\n",
    "Ytr = le.fit_transform(ytr)\n",
    "Yts = le.transform(yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(Xtr, Ytr)\n",
    "predictions = model.predict(Xts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.865961\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_multi_classification(Yts, predictions)\n",
    "print(\"Accuracy: %f\" % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
