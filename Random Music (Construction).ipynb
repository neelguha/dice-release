{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from fuzzywuzzy import fuzz\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import random \n",
    "\n",
    "from knowledge_graph import KG\n",
    "from task_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from data/uniform/construction...\n",
      "Loaded 718268 triples.\n"
     ]
    }
   ],
   "source": [
    "kg = KG(\"data/uniform/construction\")\n",
    "#kg = KG(\"data/popular/construction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: entity_matching\n",
      "entity_matching (train): 3159 samples\n",
      "entity_matching (valid): 395 samples\n",
      "entity_matching (test): 790 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kg.load_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Matching Task\n",
    "\n",
    "Our baseline consists of string matching on names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates(triples, test_x):\n",
    "    \"\"\" The entity matching task consists of mapping muiscbrainz entities to wikidata entities. \n",
    "    In order to make comparisons feasible, we first recommend performing a candidate generation step, where\n",
    "    we generate a list of likely wikidata candidates for every musicbrainz entity we seek to match.\n",
    "    \n",
    "    Args:\n",
    "        triples (list): list of all triples in the KG\n",
    "        test_x: all unknown musicbrainz entities in the test split\n",
    "    \"\"\"\n",
    "    mbz2wd_arcs = {\n",
    "        'name': ['name', 'short name', 'official name', 'birth name', 'family name'],\n",
    "        'title': ['name'],\n",
    "    }\n",
    "    \n",
    "    arcs2save = set()\n",
    "    for k, v in mbz2wd_arcs.items():\n",
    "        arcs2save.add(k)\n",
    "        for vv in v:\n",
    "            arcs2save.add(vv)\n",
    "        \n",
    "    entity2source = {} \n",
    "    entity2features = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    # collect features for each entity \n",
    "    print(\"Collecting Features\")\n",
    "    for head, arc, tail, tail_type, source in tqdm_notebook(triples):\n",
    "        entity2source[head] = source\n",
    "        if arc in arcs2save:\n",
    "            entity2features[head][arc].append(tail)\n",
    "\n",
    "    # generate candidates \n",
    "    candidate_scores = defaultdict(lambda: defaultdict(int))\n",
    "    print(\"Scoring candidates\")\n",
    "    \n",
    "    for mbz_entity in tqdm_notebook(test_x): \n",
    "        for candidate_entity in entity2features:\n",
    "            if not candidate_entity in entity2features:\n",
    "                continue\n",
    "                \n",
    "            if not mbz_entity in entity2features:\n",
    "                continue\n",
    "\n",
    "            # skip candidate if it belongs to musicbrainz\n",
    "            if entity2source[candidate_entity] == 'musicbrainz':\n",
    "                continue \n",
    "            \n",
    "            candidate_features = entity2features[candidate_entity]\n",
    "            \n",
    "    \n",
    "            '''print(\"Source entity:\",mbz_entity, entity2source[mbz_entity])\n",
    "            print(\"Source features:\",entity2features[mbz_entity])\n",
    "            print(\"Candidate:\", candidate_entity, entity2source[candidate_entity])\n",
    "            print(\"Candidate features:\", candidate_features)'''\n",
    "            score = 0\n",
    "            for off_feature_name, usda_feature_name_list in mbz2wd_arcs.items():\n",
    "                max_score = 0\n",
    "                for usda_feature_name in usda_feature_name_list:\n",
    "                    for candidate_val in candidate_features.get(usda_feature_name, []):\n",
    "                        for off_val in entity2features[mbz_entity].get(off_feature_name, []):\n",
    "                            max_score = max(fuzz.ratio(off_val, candidate_val), max_score)\n",
    "                score += max_score \n",
    "            candidate_scores[mbz_entity][candidate_entity] = score\n",
    "    return candidate_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50df4f29b414404b65f48174b05ab81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=718268), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring candidates\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41195aadbff4254a8855f01100fdf60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "candidates = generate_candidates(kg.triples, kg.tasks['entity_matching']['test']['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict top scoring candidates \n",
    "unfiltered_predictions = {} \n",
    "all_scores = []\n",
    "for mbz_entity in kg.tasks['entity_matching']['test']['X']:\n",
    "    max_score = 0\n",
    "    max_candidate = \"\"\n",
    "    for candidate, score in candidates[mbz_entity].items():\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_candidate = candidate\n",
    "    all_scores.append(max_score)\n",
    "    unfiltered_predictions[mbz_entity] = (max_candidate, max_score)\n",
    "\n",
    "# use median score as threshold \n",
    "threshold = sorted(all_scores)[int(len(all_scores) / 2)]\n",
    "\n",
    "filtered_predictions = {}\n",
    "for mbz_entity, candidate_tuple in unfiltered_predictions.items():\n",
    "    candidate, score = candidate_tuple\n",
    "    if score < threshold:\n",
    "        filtered_predictions[mbz_entity] = \"None\"\n",
    "    else:\n",
    "        filtered_predictions[mbz_entity] = candidate\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.558559. Recall: 0.822281. F1: 0.665236\n"
     ]
    }
   ],
   "source": [
    "X = kg.tasks['entity_matching']['test']['X']\n",
    "Y = kg.tasks['entity_matching']['test']['Y']\n",
    "precision, recall, f1 = evaluate_entity_matching(filtered_predictions, X, Y)\n",
    "print(\"Precision: %f. Recall: %f. F1: %f\" % (precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
